{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7d35e7-42b9-4ac4-8130-f54bd4347f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31881d0b-a0a1-4c44-917d-ae2913acc374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "# Load MovieLens dataset\n",
    "movies_df = pd.read_csv('C://Users//xpati//Documents//TFG//ml-latest-small//movies.csv')\n",
    "ratings_df = pd.read_csv('C://Users//xpati//Documents//TFG//ml-latest-small//ratings.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(movies_df.head())\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a355e275-95bc-4197-93f8-ae0cee50e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610\n",
      "Number of movies: 9724\n"
     ]
    }
   ],
   "source": [
    "# Label encoding of user and movie IDs\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['userId'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['movieId'] = movie_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "# Get number of unique users and movies\n",
    "n_users = len(user_encoder.classes_)\n",
    "n_movies = len(movie_encoder.classes_)\n",
    "\n",
    "print(f'Number of users: {n_users}')\n",
    "print(f'Number of movies: {n_movies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88982cc0-2351-4186-952f-6da11723040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, ratings_df, n_users, n_movies):\n",
    "        self.users = ratings_df['userId'].values\n",
    "        self.movies = ratings_df['movieId'].values\n",
    "        self.ratings = ratings_df['rating'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.users[idx], dtype=torch.long), \\\n",
    "               torch.tensor(self.movies[idx], dtype=torch.long), \\\n",
    "               torch.tensor(self.ratings[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ed84d0-1de4-4ebb-9fdb-21a15db3acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCollaborativeFiltering(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, embedding_dim=50, hidden_dim=128):\n",
    "        super(NeuralCollaborativeFiltering, self).__init__()\n",
    "        \n",
    "        # Embedding layers for users and movies\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, embedding_dim)\n",
    "        \n",
    "        # MLP layers for neural network\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, movie):\n",
    "        # Get embeddings\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        movie_embedded = self.movie_embedding(movie)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        x = torch.cat([user_embedded, movie_embedded], dim=1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        return self.mlp(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ec3c8e-7ddf-4df9-bb14-4599c3e52e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_df, val_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for train and validation\n",
    "train_dataset = MovieLensDataset(train_df, n_users, n_movies)\n",
    "val_dataset = MovieLensDataset(val_df, n_users, n_movies)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6f75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:13:05] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:13:05] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:13:05] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 17:13:07] CPU Model on constant consumption mode: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz\n",
      "[codecarbon INFO @ 17:13:07] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:13:07] No GPU found.\n",
      "[codecarbon INFO @ 17:13:07] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:13:07]   Platform system: Windows-10-10.0.26100-SP0\n",
      "[codecarbon INFO @ 17:13:07]   Python version: 3.8.8\n",
      "[codecarbon INFO @ 17:13:07]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 17:13:07]   Available RAM : 15.747 GB\n",
      "[codecarbon INFO @ 17:13:07]   CPU count: 8\n",
      "[codecarbon INFO @ 17:13:07]   CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz\n",
      "[codecarbon INFO @ 17:13:07]   GPU count: None\n",
      "[codecarbon INFO @ 17:13:07]   GPU model: None\n",
      "[codecarbon INFO @ 17:13:09] Saving emissions data to file C:\\Users\\xpati\\Documents\\TFG\\TFG_GCED\\Modelos\\NCF (neural-collaborative-filtering-recommender)\\emissions.csv\n",
      "[codecarbon INFO @ 17:13:17] Energy consumed for RAM : 0.000013 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:17] Energy consumed for all CPUs : 0.000027 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:17] 0.000040 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:17] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 1.2742\n",
      "Emissions for Epoch 1: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:13:25] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:13:25] Energy consumed for RAM : 0.000027 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:25] Energy consumed for all CPUs : 0.000057 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:25] 0.000083 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:25] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 0.8231\n",
      "Emissions for Epoch 2: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:13:33] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:13:33] Energy consumed for RAM : 0.000040 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:33] Energy consumed for all CPUs : 0.000085 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:33] 0.000125 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:33] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 0.7546\n",
      "Emissions for Epoch 3: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:13:41] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:13:41] Energy consumed for RAM : 0.000053 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:41] Energy consumed for all CPUs : 0.000112 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:41] 0.000165 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:41] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 0.7067\n",
      "Emissions for Epoch 4: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:13:49] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:13:49] Energy consumed for RAM : 0.000065 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:49] Energy consumed for all CPUs : 0.000138 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:49] 0.000204 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:49] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 0.6697\n",
      "Emissions for Epoch 5: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:13:56] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:13:56] Energy consumed for RAM : 0.000077 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:13:56] Energy consumed for all CPUs : 0.000164 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:13:56] 0.000241 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:13:56] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 0.6391\n",
      "Emissions for Epoch 6: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:14:03] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:14:03] Energy consumed for RAM : 0.000090 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:14:03] Energy consumed for all CPUs : 0.000190 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:14:03] 0.000279 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:14:04] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 0.6128\n",
      "Emissions for Epoch 7: 0.0000 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:14:11] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:14:11] Energy consumed for RAM : 0.000101 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:14:11] Energy consumed for all CPUs : 0.000215 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:14:11] 0.000316 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:14:11] 0.000890 g.CO2eq/s mean an estimation of 28.05540132477771 kg.CO2eq/year\n",
      "[codecarbon WARNING @ 17:14:11] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 0.5880\n",
      "Emissions for Epoch 8: 0.0001 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:14:18] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:14:18] Energy consumed for RAM : 0.000113 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:14:18] Energy consumed for all CPUs : 0.000240 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:14:18] 0.000353 kWh of electricity used since the beginning.\n",
      "[codecarbon WARNING @ 17:14:18] Already started tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 0.5650\n",
      "Emissions for Epoch 9: 0.0001 kg CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:14:25] Tracker already stopped !\n",
      "[codecarbon INFO @ 17:14:25] Energy consumed for RAM : 0.000125 kWh. RAM Power : 5.905032634735107 W\n",
      "[codecarbon INFO @ 17:14:25] Energy consumed for all CPUs : 0.000264 kWh. Total CPU Power : 12.5 W\n",
      "[codecarbon INFO @ 17:14:25] 0.000389 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Training Loss: 0.5432\n",
      "Emissions for Epoch 10: 0.0001 kg CO2\n",
      "Total emissions during training: 0.0001 kg CO2\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = NeuralCollaborativeFiltering(n_users, n_movies, embedding_dim=50, hidden_dim=128)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the CodeCarbon tracker\n",
    "tracker = EmissionsTracker()\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Start tracking emissions for this epoch\n",
    "    tracker.start()\n",
    "    \n",
    "    for user, movie, rating in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(user, movie)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, rating)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Stop tracking emissions for this epoch\n",
    "    emissions = tracker.stop()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Training Loss: {avg_train_loss:.4f}')\n",
    "    print(f'Emissions for Epoch {epoch + 1}: {emissions:.4f} kg CO2')\n",
    "\n",
    "# Final emissions report\n",
    "total_emissions = tracker.final_emissions\n",
    "print(f'Total emissions during training: {total_emissions:.4f} kg CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d2a821-225d-489b-8276-87b5e8802b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8480\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "model.eval()\n",
    "total_val_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user, movie, rating in val_loader:\n",
    "        output = model(user, movie)\n",
    "        loss = criterion(output, rating)\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "avg_val_loss = total_val_loss / len(val_loader)\n",
    "print(f'Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899b5b55-619e-4bff-910d-3d74b4c85d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.9216\n",
      "Validation MAE: 0.7060\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate RMSE and MAE\n",
    "def evaluate_metrics(model, val_loader):\n",
    "    model.eval()\n",
    "    total_squared_error = 0\n",
    "    total_absolute_error = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, movie, rating in val_loader:\n",
    "            # Forward pass\n",
    "            output = model(user, movie)\n",
    "            \n",
    "            # Calculate squared error and absolute error\n",
    "            squared_error = (output - rating) ** 2\n",
    "            absolute_error = torch.abs(output - rating)\n",
    "            \n",
    "            # Accumulate total errors\n",
    "            total_squared_error += squared_error.sum().item()\n",
    "            total_absolute_error += absolute_error.sum().item()\n",
    "            total_samples += len(rating)\n",
    "    \n",
    "    # Compute RMSE and MAE\n",
    "    rmse = np.sqrt(total_squared_error / total_samples)\n",
    "    mae = total_absolute_error / total_samples\n",
    "    \n",
    "    return rmse, mae\n",
    "\n",
    "# Evaluate RMSE and MAE on validation data\n",
    "rmse, mae = evaluate_metrics(model, val_loader)\n",
    "print(f'Validation RMSE: {rmse:.4f}')\n",
    "print(f'Validation MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebc21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
