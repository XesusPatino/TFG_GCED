{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LightGCN (Light Graph Convolutional Network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 6022, Number of Items: 3043\n",
      "\n",
      "Starting LightGCN training...\n",
      "778/778 [==============================] - 1162s 1s/step - loss: 0.3994\n",
      "Epoch 1/10 completed. Average loss: 0.399352\n",
      "778/778 [==============================] - 1147s 1s/step - loss: 0.3165\n",
      "Epoch 2/10 completed. Average loss: 0.316469\n",
      "778/778 [==============================] - 1134s 1s/step - loss: 0.2828\n",
      "Epoch 3/10 completed. Average loss: 0.282818\n",
      "778/778 [==============================] - 1133s 1s/step - loss: 0.2644\n",
      "Epoch 4/10 completed. Average loss: 0.264376\n",
      "778/778 [==============================] - 1134s 1s/step - loss: 0.2530\n",
      "Epoch 5/10 completed. Average loss: 0.252991\n",
      "778/778 [==============================] - 1131s 1s/step - loss: 0.2448\n",
      "Epoch 6/10 completed. Average loss: 0.244751\n",
      "778/778 [==============================] - 1137s 1s/step - loss: 0.2378\n",
      "Epoch 7/10 completed. Average loss: 0.237764\n",
      "778/778 [==============================] - 1173s 2s/step - loss: 0.2317\n",
      "Epoch 8/10 completed. Average loss: 0.231672\n",
      "778/778 [==============================] - 1185s 2s/step - loss: 0.2256\n",
      "Epoch 9/10 completed. Average loss: 0.225584\n",
      "778/778 [==============================] - 1205s 2s/step - loss: 0.2202\n",
      "Epoch 10/10 completed. Average loss: 0.220202\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test data...\n",
      "\n",
      "Evaluation Results (k=20):\n",
      "  Recall@20:    0.132931\n",
      "  NDCG@20:      0.288301\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.utils import Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_mydataset(train_file, test_file, val_file):\n",
    "    def read_json(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return [set(x) for x in json.load(f)]\n",
    "\n",
    "    train_list = read_json(train_file)\n",
    "    test_list = read_json(test_file)\n",
    "    val_list = read_json(val_file)\n",
    "\n",
    "    train_items = {item for items in train_list for item in items}\n",
    "\n",
    "    def filter_orphans(data_list, valid_items):\n",
    "        # remove items not appear in train set\n",
    "        return [{item for item in items if item in valid_items} for items in data_list]\n",
    "\n",
    "    test_list = filter_orphans(test_list, train_items)\n",
    "    val_list = filter_orphans(val_list, train_items)\n",
    "\n",
    "    n_users = len(train_list)\n",
    "    n_items = max(train_items) + 1 if train_items else 0\n",
    "\n",
    "    return train_list, test_list, val_list, n_users, n_items\n",
    "\n",
    "def build_adjacency_matrix(train_data, n_users, n_items):\n",
    "    R_dok = sp.dok_matrix((n_users, n_items), dtype=np.float32)\n",
    "    for u, items in enumerate(train_data):\n",
    "        for i in items:\n",
    "            R_dok[u, i] = 1.0\n",
    "    R_csr = R_dok.tocsr()\n",
    "\n",
    "    adj_size = n_users + n_items\n",
    "    adj_dok = sp.dok_matrix((adj_size, adj_size), dtype=np.float32)\n",
    "    # R in the upper-right block\n",
    "    adj_dok[:n_users, n_users:] = R_csr\n",
    "    # R^T in the lower-left block\n",
    "    adj_dok[n_users:, :n_users] = R_csr.transpose()\n",
    "    return adj_dok.tocsr()\n",
    "\n",
    "\n",
    "def normalize_adj_sym(adj_mat):\n",
    "    # symmetric normalization: D^-1/2 * A * D^-1/2.\n",
    "    rowsum = np.array(adj_mat.sum(axis=1)).flatten() + 1e-9\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.0\n",
    "    D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return D_inv_sqrt.dot(adj_mat).dot(D_inv_sqrt)\n",
    "\n",
    "class LightGCNModel(tf.keras.Model):\n",
    "    def __init__(self, n_users, n_items, adj_mat, n_layers=3, emb_dim=64, decay=1e-4, use_personalized_alpha=False):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.adj_mat = adj_mat  # TF SparseTensor\n",
    "        self.n_layers = n_layers\n",
    "        self.emb_dim = emb_dim\n",
    "        self.decay = decay\n",
    "        self.use_personalized_alpha = use_personalized_alpha\n",
    "\n",
    "        initializer = tf.initializers.GlorotUniform()\n",
    "        self.user_embedding = self.add_weight(\n",
    "            name='user_embedding',\n",
    "            shape=(n_users, emb_dim),\n",
    "            initializer=initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "        self.item_embedding = self.add_weight(\n",
    "            name='item_embedding',\n",
    "            shape=(n_items, emb_dim),\n",
    "            initializer=initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        if use_personalized_alpha:\n",
    "            self.alpha_mlp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(n_layers + 1, activation='softmax')\n",
    "            ])\n",
    "        \n",
    "        # node attribute prediction (auxiliary task)\n",
    "        self.attribute_predictor = tf.keras.layers.Dense(emb_dim, activation='relu', name=\"attribute_predictor\")\n",
    "\n",
    "\n",
    "    def call(self, embeddings, mask_prob=0.2):\n",
    "        user_emb, item_emb = embeddings\n",
    "        all_emb = tf.concat([user_emb, item_emb], axis=0)\n",
    "        emb_list = [all_emb]\n",
    "    \n",
    "        # propagation layers\n",
    "        for _ in range(self.n_layers):\n",
    "            all_emb = tf.sparse.sparse_dense_matmul(self.adj_mat, all_emb)\n",
    "            emb_list.append(all_emb)\n",
    "    \n",
    "        # combine embeddings from different layers\n",
    "        if not self.use_personalized_alpha:\n",
    "            alpha_k = 1.0 / (self.n_layers + 1)\n",
    "            alpha_weights = [alpha_k] * (self.n_layers + 1)\n",
    "            alpha_weights = tf.convert_to_tensor(alpha_weights, dtype=tf.float32)\n",
    "            alpha_weights = tf.reshape(alpha_weights, (-1, 1, 1))\n",
    "            stacked_emb = tf.stack(emb_list, axis=0)\n",
    "            combined_emb = tf.reduce_sum(stacked_emb * alpha_weights, axis=0)\n",
    "        else:\n",
    "            alpha = self.alpha_mlp(emb_list[0])\n",
    "            alpha = tf.expand_dims(alpha, axis=-1)\n",
    "            stacked_emb = tf.stack(emb_list, axis=0)\n",
    "            combined_emb = tf.reduce_sum(stacked_emb * alpha, axis=0)\n",
    "    \n",
    "        user_final, item_final = tf.split(combined_emb, [self.n_users, self.n_items], axis=0)\n",
    "    \n",
    "        # node attribute prediction\n",
    "        masked_user_emb, mask = mask_embeddings(user_final, mask_prob)\n",
    "        predicted_attributes = self.attribute_predictor(masked_user_emb)\n",
    "        return user_final, item_final, masked_user_emb, predicted_attributes, mask\n",
    "\n",
    "\n",
    "    def recommend(self, user_ids, k=10):\n",
    "        user_final, item_final, _, _, _ = self((self.user_embedding, self.item_embedding))\n",
    "        user_vecs = tf.gather(user_final, user_ids)\n",
    "    \n",
    "        all_recs = []\n",
    "        for idx, uid in enumerate(user_ids):\n",
    "            u_vec = user_vecs[idx:idx + 1]\n",
    "            scores = tf.matmul(u_vec, item_final, transpose_b=True)  # (1, n_items)\n",
    "            scores_np = scores.numpy().flatten()\n",
    "            idx_topk = np.argsort(scores_np)[::-1][:k]\n",
    "            score_topk = scores_np[idx_topk]\n",
    "            for item_id, sc in zip(idx_topk, score_topk):\n",
    "                all_recs.append((int(uid), int(item_id), float(sc)))\n",
    "        return all_recs\n",
    "\n",
    "def mask_embeddings(embeddings, mask_prob=0.2):\n",
    "    mask = tf.cast(tf.random.uniform(embeddings.shape) > mask_prob, tf.float32)\n",
    "    masked_embeddings = embeddings * mask\n",
    "    return masked_embeddings, mask\n",
    "\n",
    "\n",
    "def sample_neg(pos_items, n_items, strategy='random'):\n",
    "    if strategy == 'random':\n",
    "        neg_item = random.randint(0, n_items - 1)\n",
    "        while neg_item in pos_items:\n",
    "            neg_item = random.randint(0, n_items - 1)\n",
    "    return neg_item\n",
    "\n",
    "\n",
    "def train_lightgcn(model, train_data, n_users, n_items, batch_size=1024, epochs=10, initial_lr=1e-2, k=20):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # (user, item) pairs from train_data\n",
    "    train_pairs = [(u, i) for u in range(n_users) for i in train_data[u]]\n",
    "    steps_per_epoch = len(train_pairs) // batch_size + (len(train_pairs) % batch_size != 0)\n",
    "\n",
    "    epoch_losses = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        random.shuffle(train_pairs)\n",
    "        progbar = Progbar(steps_per_epoch)\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for step in range(steps_per_epoch):\n",
    "            batch_slice = train_pairs[step * batch_size:(step + 1) * batch_size]\n",
    "            users = [u for (u, _) in batch_slice]\n",
    "            pos_items = [i for (_, i) in batch_slice]\n",
    "            neg_items = [sample_neg(train_data[u], n_items) for (u, _) in batch_slice]\n",
    "\n",
    "            users = np.array(users, dtype=np.int32)\n",
    "            pos_items = np.array(pos_items, dtype=np.int32)\n",
    "            neg_items = np.array(neg_items, dtype=np.int32)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                user_emb, item_emb, masked_user_emb, predicted_attributes, mask = model(\n",
    "                    (model.user_embedding, model.item_embedding)\n",
    "                )\n",
    "                u_emb = tf.nn.embedding_lookup(user_emb, users)\n",
    "                pos_emb = tf.nn.embedding_lookup(item_emb, pos_items)\n",
    "                neg_emb = tf.nn.embedding_lookup(item_emb, neg_items)\n",
    "            \n",
    "                # BPR loss: mean( softplus(neg_score - pos_score) )\n",
    "                pos_scores = tf.reduce_sum(u_emb * pos_emb, axis=1)\n",
    "                neg_scores = tf.reduce_sum(u_emb * neg_emb, axis=1)\n",
    "                mf_loss = tf.reduce_mean(tf.nn.softplus(neg_scores - pos_scores))\n",
    "            \n",
    "                # node attribute prediction loss\n",
    "                attribute_loss = tf.reduce_mean(tf.square(masked_user_emb - predicted_attributes) * mask)\n",
    "            \n",
    "                # L2 Regularization\n",
    "                reg_loss = model.decay * (\n",
    "                    tf.nn.l2_loss(u_emb) + tf.nn.l2_loss(pos_emb) + tf.nn.l2_loss(neg_emb)\n",
    "                ) / batch_size\n",
    "            \n",
    "                # total loss\n",
    "                loss = mf_loss + reg_loss + 0.1 * attribute_loss  # Weighted auxiliary loss\n",
    "\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            epoch_loss += loss.numpy()\n",
    "            progbar.add(1, values=[('loss', float(loss))])\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / steps_per_epoch\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        print(f\"Epoch {epoch}/{epochs} completed. Average loss: {avg_epoch_loss:.6f}\")\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        val_users = [u for u in range(n_users) if len(val_data[u]) > 0]\n",
    "        val_recs = model.recommend(val_users, k=k)\n",
    "        epoch_recall = recall_at_k(val_recs, val_data, k=k)\n",
    "        epoch_ndcg = ndcg(val_recs, val_data, k=k)\n",
    "\n",
    "        recall_scores.append(epoch_recall)\n",
    "        ndcg_scores.append(epoch_ndcg)\n",
    "        print(f\"Epoch {epoch}: Recall@{k}: {epoch_recall:.6f}, NDCG@{k}: {epoch_ndcg:.6f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o', linestyle='-', color='b', label=\"Loss\")\n",
    "    plt.title(\"LightGCN - Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(recall_scores) + 1), recall_scores, marker='o', linestyle='-', color='g', label=f\"Recall@{k}\")\n",
    "    plt.title(f\"LightGCN - Recall@{k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(ndcg_scores) + 1), ndcg_scores, marker='o', linestyle='-', color='r', label=f\"NDCG@{k}\")\n",
    "    plt.title(f\"LightGCN - NDCG@{k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"NDCG\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return epoch_losses, recall_scores, ndcg_scores\n",
    "\n",
    "def recall_at_k(recs, test_data, k=10):\n",
    "    user_recs = defaultdict(list)\n",
    "    for (u, i, s) in recs:\n",
    "        user_recs[u].append(i)\n",
    "    recalls = []\n",
    "    for u, items_pred in user_recs.items():\n",
    "        if len(test_data[u]) == 0:\n",
    "            continue\n",
    "        if k > 0:\n",
    "            items_pred = items_pred[:k]\n",
    "        gt = test_data[u]\n",
    "        num_hit = len(set(items_pred).intersection(gt))\n",
    "        recalls.append(num_hit / float(len(gt)))\n",
    "    return np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    rel = [1 if i in ground_truth else 0 for i in recommended[:k]]\n",
    "    ideal_rel = sorted(rel, reverse=True)\n",
    "    dcg = dcg_at_k(rel, k)\n",
    "    idcg = dcg_at_k(ideal_rel, k)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def ndcg(recs, test_data, k=10):\n",
    "    user_recs = defaultdict(list)\n",
    "    for (u, i, s) in recs:\n",
    "        user_recs[u].append(i)\n",
    "    ndcgs = []\n",
    "    for u, items_pred in user_recs.items():\n",
    "        gt = test_data[u]\n",
    "        if len(gt) == 0:\n",
    "            continue\n",
    "        ndcgs.append(ndcg_at_k(items_pred, gt, k))\n",
    "    return np.mean(ndcgs) if ndcgs else 0.0\n",
    "\n",
    "\n",
    "def evaluate_lightgcn(model, users, test_data, ks=[5, 10, 20], batch_size=2000):\n",
    "    all_recs = []\n",
    "    idx_start = 0\n",
    "    max_k = max(ks)\n",
    "    while idx_start < len(users):\n",
    "        idx_end = min(idx_start + batch_size, len(users))\n",
    "        user_batch = users[idx_start:idx_end]\n",
    "        recs_chunk = model.recommend(user_batch, k=max_k)\n",
    "        all_recs.extend(recs_chunk)\n",
    "        idx_start = idx_end\n",
    "\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        rec = recall_at_k(all_recs, test_data, k=k)\n",
    "        ndcg_ = ndcg(all_recs, test_data, k=k)\n",
    "        results[k] = (rec, ndcg_)\n",
    "        print(f\"\\nEvaluation Results (k={k}):\")\n",
    "        print(f\"  Recall@{k}:    {rec:.6f}\")\n",
    "        print(f\"  NDCG@{k}:      {ndcg_:.6f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "train_file = 'C:/Users/xpati/Documents/TFG/ml-1m/train_data.json'\n",
    "test_file = 'C:/Users/xpati/Documents/TFG/ml-1m/test_data.json'\n",
    "val_file = 'C:/Users/xpati/Documents/TFG/ml-1m/validation_data.json'\n",
    "\n",
    "train_data, test_data, val_data, n_users, n_items = load_mydataset(\n",
    "    train_file, test_file, val_file\n",
    ")\n",
    "print(f\"Number of Users: {n_users}, Number of Items: {n_items}\")\n",
    "\n",
    "adj_csr = build_adjacency_matrix(train_data, n_users, n_items)\n",
    "norm_adj_csr = normalize_adj_sym(adj_csr)\n",
    "\n",
    "# convert to TensorFlow SparseTensor\n",
    "coo = norm_adj_csr.tocoo().astype(np.float32)\n",
    "indices = np.vstack((coo.row, coo.col)).transpose()\n",
    "A_tilde = tf.sparse.SparseTensor(indices=indices, values=coo.data, dense_shape=coo.shape)\n",
    "A_tilde = tf.sparse.reorder(A_tilde)\n",
    "\n",
    "N_LAYERS = 4\n",
    "EMBED_DIM = 64\n",
    "DECAY = 1e-3\n",
    "INITIAL_LR = 1e-2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "model = LightGCNModel(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    adj_mat=A_tilde,\n",
    "    n_layers=N_LAYERS,\n",
    "    emb_dim=EMBED_DIM,\n",
    "    decay=DECAY,\n",
    "    use_personalized_alpha=False\n",
    ")\n",
    "\n",
    "print(\"\\nStarting LightGCN training...\")\n",
    "train_lightgcn(\n",
    "    model=model,\n",
    "    train_data=train_data,\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    initial_lr=INITIAL_LR\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluating on test data...\")\n",
    "test_users = [u for u in range(n_users) if len(test_data[u]) > 0]\n",
    "_ = evaluate_lightgcn(model, test_users, test_data, ks=[20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
