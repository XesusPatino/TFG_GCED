{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc945ae2",
   "metadata": {},
   "source": [
    "# **LightGCN (Light Graph Convolutional Network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bb01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 6022, Number of Items: 3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 18:51:13] Error: Another instance of codecarbon is probably running as we find `C:\\Users\\xpati\\AppData\\Local\\Temp\\.codecarbon.lock`. Turn off the other instance to be able to run this one or use `allow_multiple_runs` or delete the file. Exiting.\n",
      "[codecarbon WARNING @ 18:51:13] Another instance of codecarbon is already running. Exiting.\n",
      "[codecarbon WARNING @ 18:51:13] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting LightGCN training...\n",
      "Inicializando trackers...\n",
      "Tracker principal iniciado correctamente\n",
      "778/778 [==============================] - 987s 1s/step - loss: 0.4971\n",
      "\n",
      "Epoch 1 Metrics:\n",
      "  Time: 996.83s\n",
      "  Memory: 567.52MB\n",
      "  CPU: 22.5%\n",
      "  Loss: 0.4971\n",
      "  Recall: 0.0818\n",
      "  NDCG: 0.2262\n",
      "Epoch 1 - Emisiones: 0.00061662 kg, Acumulado: 0.00061662 kg, Loss: 0.4971\n",
      "Recall: 0.0818\n",
      "NDCG: 0.2262\n",
      "Epoch 1/5 completed. Average loss: 0.497114\n",
      "Epoch 1: Recall@20: 0.081838, NDCG@20: 0.226155\n",
      "778/778 [==============================] - 987s 1s/step - loss: 0.4285\n",
      "\n",
      "Epoch 2 Metrics:\n",
      "  Time: 996.47s\n",
      "  Memory: 407.54MB\n",
      "  CPU: 47.6%\n",
      "  Loss: 0.4285\n",
      "  Recall: 0.0874\n",
      "  NDCG: 0.2401\n",
      "Epoch 2 - Emisiones: 0.00061550 kg, Acumulado: 0.00123213 kg, Loss: 0.4285\n",
      "Recall: 0.0874\n",
      "NDCG: 0.2401\n",
      "Epoch 2/5 completed. Average loss: 0.428528\n",
      "Epoch 2: Recall@20: 0.087409, NDCG@20: 0.240067\n",
      "778/778 [==============================] - 1076s 1s/step - loss: 0.3990\n",
      "\n",
      "Epoch 3 Metrics:\n",
      "  Time: 1086.30s\n",
      "  Memory: 433.24MB\n",
      "  CPU: 47.5%\n",
      "  Loss: 0.3990\n",
      "  Recall: 0.0953\n",
      "  NDCG: 0.2513\n",
      "Epoch 3 - Emisiones: 0.00067143 kg, Acumulado: 0.00190356 kg, Loss: 0.3990\n",
      "Recall: 0.0953\n",
      "NDCG: 0.2513\n",
      "Epoch 3/5 completed. Average loss: 0.398975\n",
      "Epoch 3: Recall@20: 0.095322, NDCG@20: 0.251340\n",
      "778/778 [==============================] - 1125s 1s/step - loss: 0.3791\n",
      "\n",
      "Epoch 4 Metrics:\n",
      "  Time: 1134.59s\n",
      "  Memory: 447.21MB\n",
      "  CPU: 52.3%\n",
      "  Loss: 0.3791\n",
      "  Recall: 0.1020\n",
      "  NDCG: 0.2634\n",
      "Epoch 4 - Emisiones: 0.00069826 kg, Acumulado: 0.00260182 kg, Loss: 0.3791\n",
      "Recall: 0.1020\n",
      "NDCG: 0.2634\n",
      "Epoch 4/5 completed. Average loss: 0.379111\n",
      "Epoch 4: Recall@20: 0.101978, NDCG@20: 0.263440\n",
      "778/778 [==============================] - 981s 1s/step - loss: 0.3656\n",
      "\n",
      "Epoch 5 Metrics:\n",
      "  Time: 989.75s\n",
      "  Memory: 295.32MB\n",
      "  CPU: 55.8%\n",
      "  Loss: 0.3656\n",
      "  Recall: 0.1059\n",
      "  NDCG: 0.2657\n",
      "Epoch 5 - Emisiones: 0.00060847 kg, Acumulado: 0.00321030 kg, Loss: 0.3656\n",
      "Recall: 0.1059\n",
      "NDCG: 0.2657\n",
      "Epoch 5/5 completed. Average loss: 0.365581\n",
      "Epoch 5: Recall@20: 0.105933, NDCG@20: 0.265664\n",
      "\n",
      "Evaluando en conjunto de prueba final...\n",
      "\n",
      "Evaluation Results (k=20):\n",
      "  Recall@20:    0.107668\n",
      "  NDCG@20:      0.269204\n",
      "\n",
      "Generando métricas finales del sistema...\n",
      "\n",
      "=== Final Training Metrics ===\n",
      "Epoch 1: Time=996.83s, Memory=567.52MB, CPU=22.5%, Loss=0.4971, Recall=0.0818, NDCG=0.2262\n",
      "Epoch 2: Time=996.47s, Memory=407.54MB, CPU=47.6%, Loss=0.4285, Recall=0.0874, NDCG=0.2401\n",
      "Epoch 3: Time=1086.30s, Memory=433.24MB, CPU=47.5%, Loss=0.3990, Recall=0.0953, NDCG=0.2513\n",
      "Epoch 4: Time=1134.59s, Memory=447.21MB, CPU=52.3%, Loss=0.3791, Recall=0.1020, NDCG=0.2634\n",
      "Epoch 5: Time=989.75s, Memory=295.32MB, CPU=55.8%, Loss=0.3656, Recall=0.1059, NDCG=0.2657\n",
      "\n",
      "=== Final Test Metrics ===\n",
      "Total Time: 5208.98s (Test: 4.69s)\n",
      "Final Memory: 319.03MB\n",
      "Final CPU: 18.7%\n",
      "Test Recall: 0.1077\n",
      "Test NDCG: 0.2692\n",
      "\n",
      "Generando gráficos y métricas de emisiones...\n",
      "\n",
      "Total CO2 Emissions: 0.000000 kg\n",
      "Métricas de emisiones guardadas en: results_lgcn/emissions_reports/emissions_metrics_LightGCN_20250427-201802.csv\n",
      "Gráfico guardado en: results_lgcn/emissions_plots/cumulative_emissions_vs_recall_LightGCN_20250427-201802.png\n",
      "Gráfico guardado en: results_lgcn/emissions_plots/metrics_by_epoch_LightGCN_20250427-201802.png\n",
      "Gráfico guardado en: results_lgcn/emissions_plots/cumulative_emissions_performance_scatter_LightGCN_20250427-201802.png\n",
      "Gráfico comparativo guardado en: results_lgcn/emissions_plots/recall_vs_ndcg_LightGCN_20250427-201802.png\n",
      "Métricas del modelo guardadas en: results_lgcn/model_metrics_20250427-201804.csv\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS FINALES DEL SISTEMA\n",
      "============================================================\n",
      "Memoria final: 511.96 MB\n",
      "CPU final: 10.30%\n",
      "Tiempo total de ejecución: 5211.99 segundos\n",
      "Recall@20 final: 0.1077\n",
      "NDCG@20 final: 0.2692\n",
      "============================================================\n",
      "Métricas finales guardadas en: results_lgcn/final_metrics_20250427-201804.csv\n",
      "\n",
      "Entrenamiento finalizado! Recall@20: 0.1077, NDCG@20: 0.2692\n",
      "\n",
      "Training and evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.utils import Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# Crear directorios para resultados\n",
    "result_path = \"results_lgcn\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "os.makedirs(f\"{result_path}/emissions_reports\", exist_ok=True)\n",
    "os.makedirs(f\"{result_path}/emissions_plots\", exist_ok=True)\n",
    "\n",
    "# Clases para seguimiento de métricas\n",
    "class SystemMetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.train_metrics = []\n",
    "        self.test_metrics = {}\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def start_epoch(self, epoch):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.current_epoch_metrics = {\n",
    "            'epoch': epoch,\n",
    "            'memory_usage_mb': psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2,\n",
    "            'cpu_usage_percent': psutil.cpu_percent(),\n",
    "        }\n",
    "        \n",
    "    def end_epoch(self, epoch, loss, recall=None, ndcg=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.current_epoch_metrics['epoch_time_sec'] = epoch_time\n",
    "        self.current_epoch_metrics['loss'] = loss\n",
    "        if recall is not None:\n",
    "            self.current_epoch_metrics['recall'] = recall\n",
    "        if ndcg is not None:\n",
    "            self.current_epoch_metrics['ndcg'] = ndcg\n",
    "        self.train_metrics.append(self.current_epoch_metrics)\n",
    "        \n",
    "        # Imprimir resumen de época\n",
    "        print(f\"\\nEpoch {epoch} Metrics:\")\n",
    "        print(f\"  Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  Memory: {self.current_epoch_metrics['memory_usage_mb']:.2f}MB\")\n",
    "        print(f\"  CPU: {self.current_epoch_metrics['cpu_usage_percent']:.1f}%\")\n",
    "        print(f\"  Loss: {loss:.4f}\")\n",
    "        if recall is not None:\n",
    "            print(f\"  Recall: {recall:.4f}\")\n",
    "        if ndcg is not None:\n",
    "            print(f\"  NDCG: {ndcg:.4f}\")\n",
    "        \n",
    "    def end_test(self, recall, ndcg=None):\n",
    "        self.test_metrics = {\n",
    "            'test_time_sec': time.time() - self.epoch_start_time,\n",
    "            'total_time_sec': time.time() - self.start_time,\n",
    "            'final_memory_usage_mb': psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2,\n",
    "            'final_cpu_usage_percent': psutil.cpu_percent(),\n",
    "            'test_recall': recall,\n",
    "        }\n",
    "        if ndcg is not None:\n",
    "            self.test_metrics['test_ndcg'] = ndcg\n",
    "        \n",
    "        # Imprimir métricas finales\n",
    "        print(\"\\n=== Final Training Metrics ===\")\n",
    "        for m in self.train_metrics:\n",
    "            metrics_str = f\"Epoch {m['epoch']}: Time={m['epoch_time_sec']:.2f}s, Memory={m['memory_usage_mb']:.2f}MB, CPU={m['cpu_usage_percent']:.1f}%, Loss={m['loss']:.4f}\"\n",
    "            if 'recall' in m:\n",
    "                metrics_str += f\", Recall={m['recall']:.4f}\"\n",
    "            if 'ndcg' in m:\n",
    "                metrics_str += f\", NDCG={m['ndcg']:.4f}\"\n",
    "            print(metrics_str)\n",
    "        \n",
    "        print(\"\\n=== Final Test Metrics ===\")\n",
    "        print(f\"Total Time: {self.test_metrics['total_time_sec']:.2f}s (Test: {self.test_metrics['test_time_sec']:.2f}s)\")\n",
    "        print(f\"Final Memory: {self.test_metrics['final_memory_usage_mb']:.2f}MB\")\n",
    "        print(f\"Final CPU: {self.test_metrics['final_cpu_usage_percent']:.1f}%\")\n",
    "        print(f\"Test Recall: {recall:.4f}\")\n",
    "        if ndcg is not None:\n",
    "            print(f\"Test NDCG: {ndcg:.4f}\")\n",
    "        \n",
    "        # Guardar métricas en CSV\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        metrics_df = pd.DataFrame(self.train_metrics)\n",
    "        metrics_df.to_csv(f\"{result_path}/system_metrics_{timestamp}.csv\", index=False)\n",
    "\n",
    "\n",
    "class EmissionsPerEpochTracker:\n",
    "    def __init__(self, result_path, model_name=\"LightGCN\"):\n",
    "        self.result_path = result_path\n",
    "        self.model_name = model_name\n",
    "        self.epoch_emissions = []\n",
    "        self.cumulative_emissions = []\n",
    "        self.epoch_recall = []\n",
    "        self.epoch_ndcg = []\n",
    "        self.epoch_loss = []\n",
    "        self.total_emissions = 0.0\n",
    "        self.trackers = {}\n",
    "        \n",
    "        # Inicializar tracker principal\n",
    "        self.main_tracker = EmissionsTracker(\n",
    "            project_name=f\"{model_name}_total\",\n",
    "            output_dir=f\"{result_path}/emissions_reports\",\n",
    "            save_to_file=True,\n",
    "            log_level=\"error\",\n",
    "            save_to_api=False,\n",
    "            tracking_mode=\"process\"\n",
    "        )\n",
    "        try:\n",
    "            self.main_tracker.start()\n",
    "            print(\"Tracker principal iniciado correctamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"Advertencia: No se pudo iniciar el tracker principal: {e}\")\n",
    "            self.main_tracker = None\n",
    "    \n",
    "    def start_epoch(self, epoch):\n",
    "        # Crear un tracker con un nombre único basado en timestamp\n",
    "        timestamp = int(time.time())\n",
    "        tracker_name = f\"{self.model_name}_epoch{epoch}_{timestamp}\"\n",
    "        \n",
    "        self.trackers[epoch] = EmissionsTracker(\n",
    "            project_name=tracker_name,\n",
    "            output_dir=f\"{self.result_path}/emissions_reports\",\n",
    "            save_to_file=True,\n",
    "            log_level=\"error\",\n",
    "            save_to_api=False,\n",
    "            tracking_mode=\"process\",\n",
    "            measure_power_secs=1,\n",
    "            allow_multiple_runs=True\n",
    "        )\n",
    "        try:\n",
    "            self.trackers[epoch].start()\n",
    "        except Exception as e:\n",
    "            print(f\"Advertencia: No se pudo iniciar el tracker para la época {epoch}: {e}\")\n",
    "            self.trackers[epoch] = None\n",
    "    \n",
    "    def end_epoch(self, epoch, loss, recall=None, ndcg=None):\n",
    "        try:\n",
    "            epoch_co2 = 0.0\n",
    "            if epoch in self.trackers and self.trackers[epoch]:\n",
    "                try:\n",
    "                    epoch_co2 = self.trackers[epoch].stop() or 0.0\n",
    "                except Exception as e:\n",
    "                    print(f\"Advertencia: Error al detener el tracker para la época {epoch}: {e}\")\n",
    "                    epoch_co2 = 0.0\n",
    "            \n",
    "            # Acumular emisiones totales\n",
    "            self.total_emissions += epoch_co2\n",
    "            \n",
    "            # Guardar datos de esta época\n",
    "            self.epoch_emissions.append(epoch_co2)\n",
    "            self.cumulative_emissions.append(self.total_emissions)\n",
    "            self.epoch_loss.append(loss)\n",
    "            if recall is not None:\n",
    "                self.epoch_recall.append(recall)\n",
    "            if ndcg is not None:\n",
    "                self.epoch_ndcg.append(ndcg)\n",
    "            \n",
    "            print(f\"Epoch {epoch} - Emisiones: {epoch_co2:.8f} kg, Acumulado: {self.total_emissions:.8f} kg, Loss: {loss:.4f}\")\n",
    "            if recall is not None:\n",
    "                print(f\"Recall: {recall:.4f}\")\n",
    "            if ndcg is not None:\n",
    "                print(f\"NDCG: {ndcg:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al medir emisiones en época {epoch}: {e}\")\n",
    "    \n",
    "    def end_training(self, final_recall, final_ndcg=None):\n",
    "        try:\n",
    "            # Detener el tracker principal\n",
    "            final_emissions = 0.0\n",
    "            if hasattr(self, 'main_tracker') and self.main_tracker:\n",
    "                try:\n",
    "                    final_emissions = self.main_tracker.stop() or 0.0\n",
    "                    print(f\"\\nTotal CO2 Emissions: {final_emissions:.6f} kg\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al detener el tracker principal: {e}\")\n",
    "                    final_emissions = self.total_emissions\n",
    "            else:\n",
    "                final_emissions = self.total_emissions\n",
    "            \n",
    "            # Asegurarse de que todos los trackers estén detenidos\n",
    "            for epoch, tracker in self.trackers.items():\n",
    "                if tracker is not None:\n",
    "                    try:\n",
    "                        tracker.stop()\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # Si no hay datos de emisiones por época pero tenemos emisiones totales,\n",
    "            # crear al menos una entrada para gráficos\n",
    "            if not self.epoch_emissions and final_emissions > 0:\n",
    "                self.epoch_emissions = [final_emissions]\n",
    "                self.cumulative_emissions = [final_emissions]\n",
    "                if final_recall is not None:\n",
    "                    self.epoch_recall = [final_recall]\n",
    "                if final_ndcg is not None:\n",
    "                    self.epoch_ndcg = [final_ndcg]\n",
    "            \n",
    "            # Si no hay datos, salir\n",
    "            if not self.epoch_emissions:\n",
    "                print(\"No hay datos de emisiones para graficar\")\n",
    "                return\n",
    "            \n",
    "            # Asegurarse de que tengamos un Recall final si no se rastreó por época\n",
    "            if not self.epoch_recall and final_recall is not None:\n",
    "                self.epoch_recall = [final_recall] * len(self.epoch_emissions)\n",
    "            \n",
    "            # Crear dataframe con todos los datos\n",
    "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            df = pd.DataFrame({\n",
    "                'epoch': range(len(self.epoch_emissions)),\n",
    "                'epoch_emissions_kg': self.epoch_emissions,\n",
    "                'cumulative_emissions_kg': self.cumulative_emissions,\n",
    "                'loss': self.epoch_loss if self.epoch_loss else [0.0] * len(self.epoch_emissions),\n",
    "                'recall': self.epoch_recall if self.epoch_recall else [None] * len(self.epoch_emissions),\n",
    "                'ndcg': self.epoch_ndcg if self.epoch_ndcg else [None] * len(self.epoch_emissions)\n",
    "            })\n",
    "            \n",
    "            emissions_file = f'{self.result_path}/emissions_reports/emissions_metrics_{self.model_name}_{timestamp}.csv'\n",
    "            df.to_csv(emissions_file, index=False)\n",
    "            print(f\"Métricas de emisiones guardadas en: {emissions_file}\")\n",
    "            \n",
    "            # Graficar las relaciones\n",
    "            self.plot_emissions_vs_metrics(timestamp, final_recall, final_ndcg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar gráficos de emisiones: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def plot_emissions_vs_metrics(self, timestamp, final_recall=None, final_ndcg=None):\n",
    "        \"\"\"Genera gráficos para emisiones vs métricas\"\"\"\n",
    "        \n",
    "        # Configurar estilo para fondo blanco y texto negro (más legible)\n",
    "        plt.style.use('default')\n",
    "        \n",
    "        # Usar Recall por época si está disponible, sino crear lista con el Recall final\n",
    "        if not self.epoch_recall and final_recall is not None:\n",
    "            self.epoch_recall = [final_recall] * len(self.epoch_emissions)\n",
    "        \n",
    "        try:\n",
    "            if self.epoch_recall:\n",
    "                # 1. Emisiones acumulativas vs Recall\n",
    "                plt.figure(figsize=(10, 6), facecolor='white')\n",
    "                plt.plot(self.cumulative_emissions, self.epoch_recall, 'b-', marker='o')\n",
    "                \n",
    "                # Añadir etiquetas con el número de época\n",
    "                for i, (emissions, recall) in enumerate(zip(self.cumulative_emissions, self.epoch_recall)):\n",
    "                    plt.annotate(f\"{i}\", (emissions, recall), textcoords=\"offset points\", \n",
    "                                xytext=(0,10), ha='center', fontsize=9, color='black')\n",
    "                    \n",
    "                plt.xlabel('Emisiones de CO2 acumuladas (kg)', color='black')\n",
    "                plt.ylabel('Recall@20', color='black')\n",
    "                plt.title('Relación entre Emisiones Acumuladas y Recall', color='black')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tick_params(colors='black')\n",
    "                \n",
    "                file_path = f'{self.result_path}/emissions_plots/cumulative_emissions_vs_recall_{self.model_name}_{timestamp}.png'\n",
    "                plt.savefig(file_path, facecolor='white')\n",
    "                plt.close()\n",
    "                print(f\"Gráfico guardado en: {file_path}\")\n",
    "            \n",
    "            # 2. Gráfico combinado: Emisiones por época y acumulativas\n",
    "            plt.figure(figsize=(12, 10), facecolor='white')\n",
    "            \n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(range(len(self.epoch_emissions)), self.epoch_emissions, 'r-', marker='x')\n",
    "            plt.title('Emisiones por Época', color='black')\n",
    "            plt.xlabel('Época', color='black')\n",
    "            plt.ylabel('CO2 Emissions (kg)', color='black')\n",
    "            plt.tick_params(colors='black')\n",
    "            \n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(range(len(self.cumulative_emissions)), self.cumulative_emissions, 'r-', marker='o')\n",
    "            plt.title('Emisiones Acumuladas por Época', color='black')\n",
    "            plt.xlabel('Época', color='black')\n",
    "            plt.ylabel('CO2 Emissions (kg)', color='black')\n",
    "            plt.tick_params(colors='black')\n",
    "            \n",
    "            if self.epoch_loss:\n",
    "                plt.subplot(2, 2, 3)\n",
    "                plt.plot(range(len(self.epoch_loss)), self.epoch_loss, 'g-', marker='o')\n",
    "                plt.title('Loss por Época', color='black')\n",
    "                plt.xlabel('Época', color='black')\n",
    "                plt.ylabel('Loss', color='black')\n",
    "                plt.tick_params(colors='black')\n",
    "            \n",
    "            if self.epoch_recall:\n",
    "                plt.subplot(2, 2, 4)\n",
    "                plt.plot(range(len(self.epoch_recall)), self.epoch_recall, 'b-', marker='o')\n",
    "                plt.title('Recall@20 por Época', color='black')\n",
    "                plt.xlabel('Época', color='black')\n",
    "                plt.ylabel('Recall', color='black')\n",
    "                plt.tick_params(colors='black')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            file_path = f'{self.result_path}/emissions_plots/metrics_by_epoch_{self.model_name}_{timestamp}.png'\n",
    "            plt.savefig(file_path, facecolor='white')\n",
    "            plt.close()\n",
    "            print(f\"Gráfico guardado en: {file_path}\")\n",
    "            \n",
    "            if self.epoch_recall:\n",
    "                # 3. Scatter plot de rendimiento frente a emisiones acumulativas\n",
    "                plt.figure(figsize=(10, 6), facecolor='white')\n",
    "                \n",
    "                # Ajustar tamaño de los puntos según la época\n",
    "                sizes = [(i+1)*20 for i in range(len(self.cumulative_emissions))]\n",
    "                \n",
    "                scatter = plt.scatter(self.epoch_recall, self.cumulative_emissions, \n",
    "                            color='blue', marker='o', s=sizes, alpha=0.7)\n",
    "                \n",
    "                # Añadir etiquetas de época\n",
    "                for i, (recall, em) in enumerate(zip(self.epoch_recall, self.cumulative_emissions)):\n",
    "                    plt.annotate(f\"{i}\", (recall, em), textcoords=\"offset points\", \n",
    "                                xytext=(0,5), ha='center', fontsize=9, color='black')\n",
    "                \n",
    "                plt.ylabel('Emisiones de CO2 acumuladas (kg)', color='black')\n",
    "                plt.xlabel('Recall@20', color='black')\n",
    "                plt.title('Relación entre Recall y Emisiones Acumuladas', color='black')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tick_params(colors='black')\n",
    "                \n",
    "                file_path = f'{self.result_path}/emissions_plots/cumulative_emissions_performance_scatter_{self.model_name}_{timestamp}.png'\n",
    "                plt.savefig(file_path, facecolor='white')\n",
    "                plt.close()\n",
    "                print(f\"Gráfico guardado en: {file_path}\")\n",
    "                \n",
    "            # 4. Si tenemos Recall y NDCG, crear un gráfico comparativo\n",
    "            if self.epoch_ndcg and self.epoch_recall:\n",
    "                plt.figure(figsize=(10, 6), facecolor='white')\n",
    "                plt.plot(range(len(self.epoch_recall)), self.epoch_recall, 'b-', marker='o', label='Recall@20')\n",
    "                plt.plot(range(len(self.epoch_ndcg)), self.epoch_ndcg, 'g-', marker='s', label='NDCG@20')\n",
    "                plt.title('Comparación de Recall y NDCG por Época', color='black')\n",
    "                plt.xlabel('Época', color='black')\n",
    "                plt.ylabel('Métrica', color='black')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tick_params(colors='black')\n",
    "                \n",
    "                file_path = f'{self.result_path}/emissions_plots/recall_vs_ndcg_{self.model_name}_{timestamp}.png'\n",
    "                plt.savefig(file_path, facecolor='white')\n",
    "                plt.close()\n",
    "                print(f\"Gráfico comparativo guardado en: {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar los gráficos: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Funciones originales de LightGCN\n",
    "def load_mydataset(train_file, test_file, val_file):\n",
    "    def read_json(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return [set(x) for x in json.load(f)]\n",
    "\n",
    "    train_list = read_json(train_file)\n",
    "    test_list = read_json(test_file)\n",
    "    val_list = read_json(val_file)\n",
    "\n",
    "    train_items = {item for items in train_list for item in items}\n",
    "\n",
    "    def filter_orphans(data_list, valid_items):\n",
    "        # remove items not appear in train set\n",
    "        return [{item for item in items if item in valid_items} for items in data_list]\n",
    "\n",
    "    test_list = filter_orphans(test_list, train_items)\n",
    "    val_list = filter_orphans(val_list, train_items)\n",
    "\n",
    "    n_users = len(train_list)\n",
    "    n_items = max(train_items) + 1 if train_items else 0\n",
    "\n",
    "    return train_list, test_list, val_list, n_users, n_items\n",
    "\n",
    "def build_adjacency_matrix(train_data, n_users, n_items):\n",
    "    R_dok = sp.dok_matrix((n_users, n_items), dtype=np.float32)\n",
    "    for u, items in enumerate(train_data):\n",
    "        for i in items:\n",
    "            R_dok[u, i] = 1.0\n",
    "    R_csr = R_dok.tocsr()\n",
    "\n",
    "    adj_size = n_users + n_items\n",
    "    adj_dok = sp.dok_matrix((adj_size, adj_size), dtype=np.float32)\n",
    "    # R in the upper-right block\n",
    "    adj_dok[:n_users, n_users:] = R_csr\n",
    "    # R^T in the lower-left block\n",
    "    adj_dok[n_users:, :n_users] = R_csr.transpose()\n",
    "    return adj_dok.tocsr()\n",
    "\n",
    "\n",
    "def normalize_adj_sym(adj_mat):\n",
    "    # symmetric normalization: D^-1/2 * A * D^-1/2.\n",
    "    rowsum = np.array(adj_mat.sum(axis=1)).flatten() + 1e-9\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.0\n",
    "    D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return D_inv_sqrt.dot(adj_mat).dot(D_inv_sqrt)\n",
    "\n",
    "class LightGCNModel(tf.keras.Model):\n",
    "    def __init__(self, n_users, n_items, adj_mat, n_layers=3, emb_dim=64, decay=1e-4, use_personalized_alpha=False):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.adj_mat = adj_mat  # TF SparseTensor\n",
    "        self.n_layers = n_layers\n",
    "        self.emb_dim = emb_dim\n",
    "        self.decay = decay\n",
    "        self.use_personalized_alpha = use_personalized_alpha\n",
    "\n",
    "        # Añadir semilla a los inicializadores\n",
    "        initializer = tf.initializers.GlorotUniform(seed=42)\n",
    "        self.user_embedding = self.add_weight(\n",
    "            name='user_embedding',\n",
    "            shape=(n_users, emb_dim),\n",
    "            initializer=initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "        # Usar semilla diferente para cada inicialización\n",
    "        item_initializer = tf.initializers.GlorotUniform(seed=43)\n",
    "        self.item_embedding = self.add_weight(\n",
    "            name='item_embedding',\n",
    "            shape=(n_items, emb_dim),\n",
    "            initializer=item_initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        if use_personalized_alpha:\n",
    "            alpha_initializer = tf.initializers.GlorotUniform(seed=44)\n",
    "            self.alpha_mlp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(n_layers + 1, activation='softmax', \n",
    "                                     kernel_initializer=alpha_initializer)\n",
    "            ])\n",
    "        \n",
    "        # node attribute prediction (auxiliary task)\n",
    "        attr_initializer = tf.initializers.GlorotUniform(seed=45)\n",
    "        self.attribute_predictor = tf.keras.layers.Dense(emb_dim, activation='relu', \n",
    "                                                       kernel_initializer=attr_initializer,\n",
    "                                                       name=\"attribute_predictor\")\n",
    "\n",
    "\n",
    "    def call(self, embeddings, mask_prob=0.2):\n",
    "        user_emb, item_emb = embeddings\n",
    "        all_emb = tf.concat([user_emb, item_emb], axis=0)\n",
    "        emb_list = [all_emb]\n",
    "    \n",
    "        # propagation layers\n",
    "        for _ in range(self.n_layers):\n",
    "            all_emb = tf.sparse.sparse_dense_matmul(self.adj_mat, all_emb)\n",
    "            emb_list.append(all_emb)\n",
    "    \n",
    "        # combine embeddings from different layers\n",
    "        if not self.use_personalized_alpha:\n",
    "            alpha_k = 1.0 / (self.n_layers + 1)\n",
    "            alpha_weights = [alpha_k] * (self.n_layers + 1)\n",
    "            alpha_weights = tf.convert_to_tensor(alpha_weights, dtype=tf.float32)\n",
    "            alpha_weights = tf.reshape(alpha_weights, (-1, 1, 1))\n",
    "            stacked_emb = tf.stack(emb_list, axis=0)\n",
    "            combined_emb = tf.reduce_sum(stacked_emb * alpha_weights, axis=0)\n",
    "        else:\n",
    "            alpha = self.alpha_mlp(emb_list[0])\n",
    "            alpha = tf.expand_dims(alpha, axis=-1)\n",
    "            stacked_emb = tf.stack(emb_list, axis=0)\n",
    "            combined_emb = tf.reduce_sum(stacked_emb * alpha, axis=0)\n",
    "    \n",
    "        user_final, item_final = tf.split(combined_emb, [self.n_users, self.n_items], axis=0)\n",
    "    \n",
    "        # node attribute prediction\n",
    "        masked_user_emb, mask = mask_embeddings(user_final, mask_prob)\n",
    "        predicted_attributes = self.attribute_predictor(masked_user_emb)\n",
    "        return user_final, item_final, masked_user_emb, predicted_attributes, mask\n",
    "\n",
    "\n",
    "    def recommend(self, user_ids, k=10):\n",
    "        user_final, item_final, _, _, _ = self((self.user_embedding, self.item_embedding))\n",
    "        user_vecs = tf.gather(user_final, user_ids)\n",
    "    \n",
    "        all_recs = []\n",
    "        for idx, uid in enumerate(user_ids):\n",
    "            u_vec = user_vecs[idx:idx + 1]\n",
    "            scores = tf.matmul(u_vec, item_final, transpose_b=True)  # (1, n_items)\n",
    "            scores_np = scores.numpy().flatten()\n",
    "            idx_topk = np.argsort(scores_np)[::-1][:k]\n",
    "            score_topk = scores_np[idx_topk]\n",
    "            for item_id, sc in zip(idx_topk, score_topk):\n",
    "                all_recs.append((int(uid), int(item_id), float(sc)))\n",
    "        return all_recs\n",
    "\n",
    "def mask_embeddings(embeddings, mask_prob=0.2):\n",
    "    mask = tf.cast(tf.random.uniform(embeddings.shape) > mask_prob, tf.float32)\n",
    "    masked_embeddings = embeddings * mask\n",
    "    return masked_embeddings, mask\n",
    "\n",
    "\n",
    "def sample_neg(pos_items, n_items, strategy='random'):\n",
    "    if strategy == 'random':\n",
    "        neg_item = random.randint(0, n_items - 1)\n",
    "        while neg_item in pos_items:\n",
    "            neg_item = random.randint(0, n_items - 1)\n",
    "    return neg_item\n",
    "\n",
    "\n",
    "def train_lightgcn_with_metrics(model, train_data, val_data, test_data, n_users, n_items, batch_size=1024, epochs=10, initial_lr=1e-2, k=20):\n",
    "    # Inicializar trackers\n",
    "    print(\"Inicializando trackers...\")\n",
    "    system_tracker = SystemMetricsTracker()\n",
    "    emissions_tracker = EmissionsPerEpochTracker(result_path, \"LightGCN\")\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # (user, item) pairs from train_data\n",
    "    train_pairs = [(u, i) for u in range(n_users) for i in train_data[u]]\n",
    "    steps_per_epoch = len(train_pairs) // batch_size + (len(train_pairs) % batch_size != 0)\n",
    "\n",
    "    epoch_losses = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    # Para métricas finales\n",
    "    tiempo_inicio = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Iniciar seguimiento de época\n",
    "        system_tracker.start_epoch(epoch)\n",
    "        emissions_tracker.start_epoch(epoch)\n",
    "        \n",
    "        random.shuffle(train_pairs)\n",
    "        progbar = Progbar(steps_per_epoch)\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for step in range(steps_per_epoch):\n",
    "            batch_slice = train_pairs[step * batch_size:(step + 1) * batch_size]\n",
    "            users = [u for (u, _) in batch_slice]\n",
    "            pos_items = [i for (_, i) in batch_slice]\n",
    "            neg_items = [sample_neg(train_data[u], n_items) for (u, _) in batch_slice]\n",
    "\n",
    "            users = np.array(users, dtype=np.int32)\n",
    "            pos_items = np.array(pos_items, dtype=np.int32)\n",
    "            neg_items = np.array(neg_items, dtype=np.int32)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                user_emb, item_emb, masked_user_emb, predicted_attributes, mask = model(\n",
    "                    (model.user_embedding, model.item_embedding)\n",
    "                )\n",
    "                u_emb = tf.nn.embedding_lookup(user_emb, users)\n",
    "                pos_emb = tf.nn.embedding_lookup(item_emb, pos_items)\n",
    "                neg_emb = tf.nn.embedding_lookup(item_emb, neg_items)\n",
    "            \n",
    "                # BPR loss: mean( softplus(neg_score - pos_score) )\n",
    "                pos_scores = tf.reduce_sum(u_emb * pos_emb, axis=1)\n",
    "                neg_scores = tf.reduce_sum(u_emb * neg_emb, axis=1)\n",
    "                mf_loss = tf.reduce_mean(tf.nn.softplus(neg_scores - pos_scores))\n",
    "            \n",
    "                # node attribute prediction loss\n",
    "                attribute_loss = tf.reduce_mean(tf.square(masked_user_emb - predicted_attributes) * mask)\n",
    "            \n",
    "                # L2 Regularization\n",
    "                reg_loss = model.decay * (\n",
    "                    tf.nn.l2_loss(u_emb) + tf.nn.l2_loss(pos_emb) + tf.nn.l2_loss(neg_emb)\n",
    "                ) / batch_size\n",
    "            \n",
    "                # total loss\n",
    "                loss = mf_loss + reg_loss + 0.1 * attribute_loss  # Weighted auxiliary loss\n",
    "\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            epoch_loss += loss.numpy()\n",
    "            progbar.add(1, values=[('loss', float(loss))])\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / steps_per_epoch\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        val_users = [u for u in range(n_users) if len(val_data[u]) > 0]\n",
    "        val_recs = model.recommend(val_users, k=k)\n",
    "        epoch_recall = recall_at_k(val_recs, val_data, k=k)\n",
    "        epoch_ndcg = ndcg(val_recs, val_data, k=k)\n",
    "\n",
    "        recall_scores.append(epoch_recall)\n",
    "        ndcg_scores.append(epoch_ndcg)\n",
    "        \n",
    "        # Actualizar trackers con las métricas\n",
    "        system_tracker.end_epoch(epoch, avg_epoch_loss, epoch_recall, epoch_ndcg)\n",
    "        emissions_tracker.end_epoch(epoch, avg_epoch_loss, epoch_recall, epoch_ndcg)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{epochs} completed. Average loss: {avg_epoch_loss:.6f}\")\n",
    "        print(f\"Epoch {epoch}: Recall@{k}: {epoch_recall:.6f}, NDCG@{k}: {epoch_ndcg:.6f}\")\n",
    "\n",
    "    # Evaluación final en el conjunto de pruebas\n",
    "    print(\"\\nEvaluando en conjunto de prueba final...\")\n",
    "    system_tracker.start_epoch(\"test\")\n",
    "    \n",
    "    test_users = [u for u in range(n_users) if len(test_data[u]) > 0]\n",
    "    final_metrics = evaluate_lightgcn(model, test_users, test_data, ks=[k])\n",
    "    final_recall = final_metrics[k][0]  # Recall@k\n",
    "    final_ndcg = final_metrics[k][1]    # NDCG@k\n",
    "    \n",
    "    # Finalizar seguimiento de sistemas\n",
    "    try:\n",
    "        print(\"\\nGenerando métricas finales del sistema...\")\n",
    "        system_tracker.end_test(final_recall, final_ndcg)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar métricas finales con tracker: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nGenerando gráficos y métricas de emisiones...\")\n",
    "        emissions_tracker.end_training(final_recall, final_ndcg)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar métricas de emisiones: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Guardar métricas de entrenamiento\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'epoch': list(range(1, epochs + 1)),\n",
    "        'loss': epoch_losses,\n",
    "        'recall': recall_scores,\n",
    "        'ndcg': ndcg_scores\n",
    "    })\n",
    "    \n",
    "    metrics_file = f\"{result_path}/model_metrics_{timestamp}.csv\"\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"Métricas del modelo guardadas en: {metrics_file}\")\n",
    "    \n",
    "    # Mostrar métricas finales (independientes)\n",
    "    memoria_final = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "    cpu_final = psutil.cpu_percent(interval=1.0)\n",
    "    tiempo_total = time.time() - tiempo_inicio\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MÉTRICAS FINALES DEL SISTEMA\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Memoria final: {memoria_final:.2f} MB\")\n",
    "    print(f\"CPU final: {cpu_final:.2f}%\")\n",
    "    print(f\"Tiempo total de ejecución: {tiempo_total:.2f} segundos\")\n",
    "    print(f\"Recall@{k} final: {final_recall:.4f}\")\n",
    "    print(f\"NDCG@{k} final: {final_ndcg:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Guardar las métricas finales\n",
    "    final_metrics_dict = {\n",
    "        'final_memory_mb': memoria_final,\n",
    "        'final_cpu_percent': cpu_final,\n",
    "        'total_time_sec': tiempo_total,\n",
    "        'final_recall': final_recall,\n",
    "        'final_ndcg': final_ndcg,\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    final_metrics_df = pd.DataFrame([final_metrics_dict])\n",
    "    final_metrics_file = f\"{result_path}/final_metrics_{timestamp}.csv\"\n",
    "    final_metrics_df.to_csv(final_metrics_file, index=False)\n",
    "    print(f\"Métricas finales guardadas en: {final_metrics_file}\")\n",
    "    \n",
    "    # Graficar resultados de entrenamiento\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o', linestyle='-', color='b', label=\"Loss\")\n",
    "    plt.title(\"LightGCN - Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{result_path}/training_loss_{timestamp}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(recall_scores) + 1), recall_scores, marker='o', linestyle='-', color='g', label=f\"Recall@{k}\")\n",
    "    plt.title(f\"LightGCN - Recall@{k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{result_path}/recall_{timestamp}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(ndcg_scores) + 1), ndcg_scores, marker='o', linestyle='-', color='r', label=f\"NDCG@{k}\")\n",
    "    plt.title(f\"LightGCN - NDCG@{k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"NDCG\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{result_path}/ndcg_{timestamp}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\nEntrenamiento finalizado! Recall@{k}: {final_recall:.4f}, NDCG@{k}: {final_ndcg:.4f}\")\n",
    "    \n",
    "    return epoch_losses, recall_scores, ndcg_scores, final_recall, final_ndcg\n",
    "\n",
    "# Funciones de evaluación existentes\n",
    "def recall_at_k(recs, test_data, k=10):\n",
    "    user_recs = defaultdict(list)\n",
    "    for (u, i, s) in recs:\n",
    "        user_recs[u].append(i)\n",
    "    recalls = []\n",
    "    for u, items_pred in user_recs.items():\n",
    "        if len(test_data[u]) == 0:\n",
    "            continue\n",
    "        if k > 0:\n",
    "            items_pred = items_pred[:k]\n",
    "        gt = test_data[u]\n",
    "        num_hit = len(set(items_pred).intersection(gt))\n",
    "        recalls.append(num_hit / float(len(gt)))\n",
    "    return np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    rel = [1 if i in ground_truth else 0 for i in recommended[:k]]\n",
    "    ideal_rel = sorted(rel, reverse=True)\n",
    "    dcg = dcg_at_k(rel, k)\n",
    "    idcg = dcg_at_k(ideal_rel, k)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def ndcg(recs, test_data, k=10):\n",
    "    user_recs = defaultdict(list)\n",
    "    for (u, i, s) in recs:\n",
    "        user_recs[u].append(i)\n",
    "    ndcgs = []\n",
    "    for u, items_pred in user_recs.items():\n",
    "        gt = test_data[u]\n",
    "        if len(gt) == 0:\n",
    "            continue\n",
    "        ndcgs.append(ndcg_at_k(items_pred, gt, k))\n",
    "    return np.mean(ndcgs) if ndcgs else 0.0\n",
    "\n",
    "def evaluate_lightgcn(model, users, test_data, ks=[5, 10, 20], batch_size=2000):\n",
    "    all_recs = []\n",
    "    idx_start = 0\n",
    "    max_k = max(ks)\n",
    "    while idx_start < len(users):\n",
    "        idx_end = min(idx_start + batch_size, len(users))\n",
    "        user_batch = users[idx_start:idx_end]\n",
    "        recs_chunk = model.recommend(user_batch, k=max_k)\n",
    "        all_recs.extend(recs_chunk)\n",
    "        idx_start = idx_end\n",
    "\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        rec = recall_at_k(all_recs, test_data, k=k)\n",
    "        ndcg_ = ndcg(all_recs, test_data, k=k)\n",
    "        results[k] = (rec, ndcg_)\n",
    "        print(f\"\\nEvaluation Results (k={k}):\")\n",
    "        print(f\"  Recall@{k}:    {rec:.6f}\")\n",
    "        print(f\"  NDCG@{k}:      {ndcg_:.6f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Función principal para ejecutar todo\n",
    "def run_lightgcn_with_metrics():\n",
    "    train_file = 'C:/Users/xpati/Documents/TFG/ml-1m/train_data.json'\n",
    "    test_file = 'C:/Users/xpati/Documents/TFG/ml-1m/test_data.json'\n",
    "    val_file = 'C:/Users/xpati/Documents/TFG/ml-1m/validation_data.json'\n",
    "\n",
    "    train_data, test_data, val_data, n_users, n_items = load_mydataset(\n",
    "        train_file, test_file, val_file\n",
    "    )\n",
    "    print(f\"Number of Users: {n_users}, Number of Items: {n_items}\")\n",
    "\n",
    "    adj_csr = build_adjacency_matrix(train_data, n_users, n_items)\n",
    "    norm_adj_csr = normalize_adj_sym(adj_csr)\n",
    "\n",
    "    # convert to TensorFlow SparseTensor\n",
    "    coo = norm_adj_csr.tocoo().astype(np.float32)\n",
    "    indices = np.vstack((coo.row, coo.col)).transpose()\n",
    "    A_tilde = tf.sparse.SparseTensor(indices=indices, values=coo.data, dense_shape=coo.shape)\n",
    "    A_tilde = tf.sparse.reorder(A_tilde)\n",
    "\n",
    "    N_LAYERS = 2\n",
    "    EMBED_DIM = 128\n",
    "    DECAY = 1e-2\n",
    "    INITIAL_LR = 1e-3\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 1024\n",
    "\n",
    "    model = LightGCNModel(\n",
    "        n_users=n_users,\n",
    "        n_items=n_items,\n",
    "        adj_mat=A_tilde,\n",
    "        n_layers=N_LAYERS,\n",
    "        emb_dim=EMBED_DIM,\n",
    "        decay=DECAY,\n",
    "        use_personalized_alpha=False\n",
    "    )\n",
    "\n",
    "    print(\"\\nStarting LightGCN training...\")\n",
    "    epoch_losses, recall_scores, ndcg_scores, final_recall, final_ndcg = train_lightgcn_with_metrics(\n",
    "        model=model,\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        test_data=test_data,\n",
    "        n_users=n_users,\n",
    "        n_items=n_items,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        initial_lr=INITIAL_LR,\n",
    "        k=20\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining and evaluation completed!\")\n",
    "    return final_recall, final_ndcg\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_lightgcn_with_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
